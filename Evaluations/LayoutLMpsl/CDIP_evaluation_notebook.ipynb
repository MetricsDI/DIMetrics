{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'di_metrics._utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-52fe7016b2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdi_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_geometric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdi_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_textual\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlevenshtein_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlc_subsequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_exact_match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdi_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdi_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_item_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_cord_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocess_pred_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'di_metrics._utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import di_metrics as dim\n",
    "from di_metrics._hed import hed\n",
    "from di_metrics._geometric import iou\n",
    "from di_metrics._textual import levenshtein_distance, lc_subsequence, str_exact_match\n",
    "from di_metrics._utils import get_dicts, get_item_df, process_cord_file,process_pred_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_geometric',\n",
       " '_hed',\n",
       " '_textual',\n",
       " 'cumulative_lcs',\n",
       " 'docbank_overlap',\n",
       " 'hed',\n",
       " 'iou',\n",
       " 'lc_subsequence',\n",
       " 'levenshtein_distance',\n",
       " 'line_item_edit_distance',\n",
       " 'str_exact_match']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import di_metrics\n",
    "dir(di_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FR = True\n",
    "cord=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_DIR = '/Users/ng492mh/Documents/DI_Metrics_proj/CORD_data/cord_data_jsons/test/'\n",
    "# layoutlm\n",
    "if not FR and not cord:\n",
    "    ListPrefix = 'item'\n",
    "    PRED_DIR = '/Users/ng492mh/Documents/DI_Metrics_proj/cdip_layoutlm_pred_psl/'\n",
    "if not FR and cord:\n",
    "    CORD_lineitems = [ \"menu.cnt\", \"menu.nm\", \"menu.price\", \"menu.unitprice\"]\n",
    "    CORD_other_in_hed = ['subtotal.subtotal_price', 'sub_total.tax_price','total.total_price']\n",
    "    PRED_DIR = '/Users/ng492mh/Documents/DI_Metrics_proj/cord_layoutlm_pred_psl_epoch7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FR\n",
    "if FR and not cord:\n",
    "    multiplier = 300\n",
    "    ListPrefix = 'Item'\n",
    "    field_mapping = {\n",
    "        'main|||vendor_name||primary_fields': 'VendorName',\n",
    "        'main|||buyer_name||primary_fields': 'CustomerName',\n",
    "        'main|||invoice_number||primary_fields': 'InvoiceId',\n",
    "        'main|||total_amount||primary_fields':'InvoiceTotal',\n",
    "        'main|||issued_date||primary_fields':'InvoiceDate',\n",
    "        'main|||item_description||line_items': 'ItemDescription', \n",
    "        'main|||item_total||line_items':'ItemTotal',\n",
    "        'main|||Item_unit_count||line_items': 'ItemCount',\n",
    "    #     'vendor_address_combined':'VendorAddress',\n",
    "    #     'buyer_address_combined': 'CustomerAddress',\n",
    "        'Description': 'ItemDescription',\n",
    "        'Amount': 'ItemTotal',\n",
    "        'Quantity': 'ItemCount',\n",
    "    }\n",
    "    PRED_DIR = '/Users/ng492mh/Downloads/FR_cdip_preds/'\n",
    "if FR and cord:\n",
    "    multiplier = 1\n",
    "    ListPrefix = 'Item'\n",
    "    field_mapping = {\n",
    "        'subtotal.subtotal_price' : 'Subtotal',\n",
    "        'sub_total.tax_price': 'Tax',\n",
    "        'total.total_price': 'Total',\n",
    "        'menu.nm': 'ItemName',\n",
    "        'menu.unitprice': 'ItemPrice',\n",
    "        'menu.cnt': 'ItemQuantity',\n",
    "        'menu.price':'ItemTotalPrice',\n",
    "        'Name': 'ItemName',\n",
    "        'Price': 'ItemPrice',\n",
    "        'Quantity': 'ItemQuantity',\n",
    "        'TotalPrice':'ItemTotalPrice'}\n",
    "    PRED_DIR = '/Users/ng492mh/Downloads/fr_CORD_test_preds/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_threshold = 25\n",
    "iou_threshold = 0.51\n",
    "pattern = re.compile('[\\W_]+')\n",
    "address_labels = set(['main|||vendor_address_street||primary_fields',\n",
    "       'main|||vendor_address_city||primary_fields',\n",
    "       'main|||vendor_address_postal_code||primary_fields',\n",
    "       'main|||vendor_address_country||primary_fields',\n",
    "       'main|||buyer_address_city||primary_fields',\n",
    "       'main|||buyer_address_street||primary_fields',\n",
    "       'main|||buyer_address_postal_code||primary_fields',\n",
    "       'main|||buyer_address_country||primary_fields'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cdip_gt(gt_file, pdf_filename=None):\n",
    "\n",
    "    with open(gt_file) as f:\n",
    "        gt_dict = json.load(f)\n",
    "\n",
    "    ## Adding most of the main fields to dataframe\n",
    "    gt_df = pd.DataFrame(gt_dict['1'])\n",
    "    gt_df['bbox'] = gt_df['bounding_box'].apply(lambda x: [x[0], x[1], x[0]+x[2], x[1] + x[3]])\n",
    "    gt_df['text'] = gt_df['bounding_box'].apply(lambda x: x[-1])\n",
    "    gt_df = gt_df.rename(columns={'classification_label': 'label'})\n",
    "    gt_df = gt_df.drop(columns=['activity_label', 'bounding_box', 'class_probability'])\n",
    "    if pdf_filename:\n",
    "        gt_df['file'] = pdf_filename\n",
    "    return gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(gt_df):\n",
    "    gt_df['X'] = gt_df['bbox'].apply(lambda x: x[0])\n",
    "    new_gt_df =pd.DataFrame()\n",
    "    for i, group in gt_df.groupby(['group_label']): \n",
    "        for label in group['label'].unique():\n",
    "            g = group[group['label'] == label]\n",
    "            if g.shape[0] > 1:\n",
    "                group_label = g.iloc[0][\"group_label\"]\n",
    "                g = g.sort_values(by='X')\n",
    "                combined_bbox = [np.inf, np.inf, -np.inf, -np.inf]\n",
    "                combined_text = \"\"\n",
    "\n",
    "                for j, row in g.iterrows():\n",
    "                    combined_bbox[0] = min(row['bbox'][0], combined_bbox[0])\n",
    "                    combined_bbox[1] = min(row['bbox'][1], combined_bbox[1])\n",
    "                    combined_bbox[2] = max(row['bbox'][2], combined_bbox[2])\n",
    "                    combined_bbox[3] = max(row['bbox'][3], combined_bbox[3])\n",
    "\n",
    "                    combined_text += row['text'] + ' '\n",
    "                new_gt_df = new_gt_df.append(pd.DataFrame([[combined_bbox, combined_text.strip(), label,group_label]], columns=['bbox','text','label','group_label']),ignore_index=True, sort=True)\n",
    "            else:\n",
    "                new_gt_df = new_gt_df.append(g.drop(columns=['X']), ignore_index=True, sort=True)\n",
    "    return new_gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_group(df, line_threshold):\n",
    "    df[\"group_label\"] = 0\n",
    "    temp_df = df.loc[df[\"label\"].apply(lambda x: ListPrefix in x), :]\n",
    "    if temp_df.shape[0] == 0:\n",
    "        return df\n",
    "    notline_df = df.loc[df[\"label\"].apply(lambda x: ListPrefix not in x), :]\n",
    "    i = 1\n",
    "    temp_df[\"Y\"] = temp_df[\"bbox\"].apply(lambda x: x[1])\n",
    "    temp_df.sort_values(by=\"Y\", inplace=True)\n",
    "    prev = temp_df.iloc[0][\"Y\"]\n",
    "    group_label = 1\n",
    "    new_temp_df = pd.DataFrame()\n",
    "    for i, row in temp_df.iterrows():\n",
    "        if row[\"Y\"] - prev <=line_threshold:\n",
    "            row[\"group_label\"] = group_label\n",
    "        else:\n",
    "            group_label += 1\n",
    "            row[\"group_label\"] = group_label\n",
    "            prev = row[\"Y\"]\n",
    "        new_temp_df = new_temp_df.append(row,ignore_index=True, sort=True)\n",
    "    \n",
    "    return new_temp_df.append(notline_df, ignore_index=True, sort=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_layoutlm_pred_file(gt_file, line_threshold, pdf_filename=None, cord=False):\n",
    "    with open(gt_file) as f:\n",
    "        gt_dict = json.load(f)\n",
    "\n",
    "    ## Adding most of the main fields to dataframe\n",
    "    gt_df = pd.DataFrame(gt_dict[\"predictions\"])\n",
    "    gt_df['bbox'] = gt_df['bounding_box'].apply(lambda x: [x[0], x[1], x[0] + x[2], x[1] + x[3]])\n",
    "    gt_df['text'] = gt_df['bounding_box'].apply(lambda x: x[-1])\n",
    "    \n",
    "    gt_df = gt_df.rename(columns={'classification_label': 'label'})\n",
    "    gt_df['label'] = gt_df['label'].apply(lambda x: x.replace(\"S-\",\"\"))\n",
    "    gt_df = gt_df[gt_df['label'] != \"No class\"]\n",
    "    if gt_df.shape[0] == 0:\n",
    "        return pd.DataFrame()\n",
    "    gt_df = gt_df[gt_df['label'].notna()]\n",
    "    gt_df = gt_df.drop(columns=['bounding_box', 'class_probability', 'PSL_classification_label', 'box_id','scores'],errors='ignore') \n",
    "    ####fixme\n",
    "    gt_df = gt_df.drop(columns=['PSL_lineitem_number'], axis=1)\n",
    "    if 'PSL_lineitem_number' in gt_df.columns:\n",
    "        gt_df = gt_df.rename(columns={'PSL_lineitem_number': 'group_label'})\n",
    "        gt_df.loc[gt_df[\"group_label\"] == \"\", \"group_label\"] = 0\n",
    "    else:\n",
    "        gt_df = assign_group(gt_df, line_threshold)\n",
    "   \n",
    "    if not cord:\n",
    "        new_gt_df = combine_text(gt_df)\n",
    "    else:\n",
    "        new_gt_df = gt_df\n",
    "    if pdf_filename:\n",
    "        new_gt_df['file'] = pdf_filename\n",
    " \n",
    "    return new_gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get matched DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_inside(y_true, y_pred):\n",
    "    xA = max(y_true[0], y_pred[0])\n",
    "    yA = max(y_true[1], y_pred[1])\n",
    "    xB = min(y_true[2], y_pred[2])\n",
    "    yB = min(y_true[3], y_pred[3])\n",
    "    inset = [xA,yA,xB,yB]\n",
    "    if all([inset[i] == y_true[i] for i in range(4)]) or all([inset[i] == y_pred[i] for i in range(4)]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_gt_pred(gt_df, pred_df):\n",
    "    gt_df.drop(columns=['file'], axis=1, inplace=True, errors='ignore')\n",
    "    pred_df.drop(columns=['file'], axis=1, inplace=True, errors='ignore')\n",
    "    gt_df[\"X\"] = gt_df['bbox'].apply(lambda x: x[0])\n",
    "    gt_df[\"Y\"] = gt_df['bbox'].apply(lambda x: x[1])\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    gt_df.rename(columns={'group_label':'gt_group_label','bbox':'gt_bbox'}, inplace=True)\n",
    "    pred_df[\"X\"] = pred_df['bbox'].apply(lambda x: x[0])\n",
    "    pred_df[\"Y\"] = pred_df['bbox'].apply(lambda x: x[1])\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    pred_df.rename(columns={'group_label':'pred_group_label','bbox':'pred_bbox'}, inplace=True)\n",
    "    # Get same (Label, X,Y,Text) data\n",
    "    common = gt_df.merge(pred_df, on=['label','text','X','Y'], how='inner')\n",
    "    common.drop(columns=[\"X\",\"Y\"], axis=1, inplace=True)\n",
    "    common.rename(columns={'text':'gt_text'}, inplace=True)\n",
    "    common.loc[:, 'pred_text'] = common.loc[:, 'gt_text']\n",
    "    gt_rest = gt_df[gt_df.gt_id.apply(lambda x: x not in common.gt_id.tolist())]\n",
    "    gt_rest.drop(columns=[\"X\",\"Y\"], axis=1, inplace=True)\n",
    "    pred_rest = pred_df[pred_df.pred_id.apply(lambda x: x not in common.pred_id.tolist())]\n",
    "    pred_rest.drop(columns=[\"X\",\"Y\"], axis=1, inplace=True)\n",
    "    \n",
    "\n",
    "    if gt_rest.shape[0] == 0:\n",
    "        gt_df.drop(columns=['gt_id'], axis=1, inplace=True)\n",
    "        pred_rest.drop(columns=['pred_id'], axis=1, inplace=True)\n",
    "        combined_df = gt_df.append(pred_rest, sort=True, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        used_gt_ids = []\n",
    "        used_pred_ids = []\n",
    "        mix_df = pd.DataFrame(columns=['label','gt_group_label','gt_text','gt_bbox','pred_text','pred_bbox','pred_group_label'])\n",
    "        add_idx = 0\n",
    "        # If there are gt data which is not in pred, check if there is similar bbox which should be the identical one.\n",
    "        for j, gt_row in gt_rest.iterrows():\n",
    "            gt_label = gt_row['label']\n",
    "            for i, pred_row in pred_rest.iterrows():\n",
    "                if pred_row['label'] == gt_label:\n",
    "                    ious = iou(gt_row['gt_bbox'], pred_row['pred_bbox']) \n",
    "                    if (ious >= iou_threshold) or (box_inside(gt_row['gt_bbox'], pred_row['pred_bbox'])):\n",
    "                        used_pred_ids.append(pred_row['pred_id'])\n",
    "                        used_gt_ids.append(gt_row['gt_id'])\n",
    "                        mix_df.loc[add_idx] = (gt_label, gt_row['gt_group_label'], gt_row['text'], gt_row['gt_bbox'],\n",
    "                                               pred_row['text'], pred_row['pred_bbox'], pred_row['pred_group_label'])\n",
    "        \n",
    "                        add_idx += 1\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "        # Append all pred data which has no matching gt data\n",
    "        pred_nomatch = pred_rest[pred_rest.pred_id.apply(lambda x: x not in used_pred_ids)]\n",
    "        pred_nomatch.rename(columns={'text':'pred_text'}, inplace=True)\n",
    "        gt_nomatch = gt_rest[gt_rest.gt_id.apply(lambda x: x not in used_gt_ids)]\n",
    "        gt_nomatch.rename(columns={'text':'gt_text'}, inplace=True)\n",
    "        combined_df = common.append([mix_df, pred_nomatch, gt_nomatch], sort=True, ignore_index=True)\n",
    "        combined_df.drop(columns=['pred_id','gt_id'], axis=1, inplace=True)\n",
    "        return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HED Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_line_items(item_df):\n",
    "    if len(item_df) == 0:\n",
    "        return []\n",
    "    ans = []\n",
    "    for i, row in item_df.sort_values(by=['mid_y']).iterrows():\n",
    "        d = {}\n",
    "        for j, col in row.iteritems():\n",
    "            if type(col) == dict:\n",
    "                d[j] = col['text']\n",
    "        ans.append(d)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_item_dic(df, cord=False, FR=False): \n",
    "    df = df[df['label'].apply(lambda x: x not in address_labels)]\n",
    "    dic = {}\n",
    "    if cord:\n",
    "        df = combine_text(df)\n",
    "    if not FR and cord:\n",
    "        # only for layoutlm pred for cord data\n",
    "        item_df = df[df['label'].apply(lambda x:x in CORD_lineitems)]\n",
    "        other_df = df[df['label'].apply(lambda x: x in CORD_other_in_hed)]\n",
    "    else:\n",
    "        item_df = df[df['label'].apply(lambda x: ListPrefix in x)]\n",
    "        other_df = df[df['label'].apply(lambda x: ListPrefix not in x)]\n",
    "    for i,row in other_df.iterrows():\n",
    "        dic[row['label']] = row['text']\n",
    "    if len(item_df) > 0:\n",
    "        item_df = get_item_df(item_df)\n",
    "    dic['Items'] = sort_line_items(item_df)\n",
    "    return dic\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule to match ground truth and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_df(PRED_DIR,GT_DIR, line_threshold=25, cord=False):\n",
    "    final_df = pd.DataFrame()\n",
    "    gt_hed_lists = []\n",
    "    pred_hed_lists = []\n",
    "    file_num = 0\n",
    "    for pred_file in os.listdir(PRED_DIR):\n",
    "        if pred_file == '.DS_Store':\n",
    "            continue         \n",
    "        if pred_file[:-5][-12:] != \"pred_grouped\":\n",
    "            continue   \n",
    "        file_prefix = pred_file[:-5][:-len(\"_abbyy_pred_grouped\")]\n",
    "        pred_file = os.path.join(PRED_DIR, pred_file)\n",
    "        if cord:\n",
    "            gt_file = os.path.join(GT_DIR, file_prefix+'.json')\n",
    "        else:\n",
    "            gt_file = os.path.join(GT_DIR, file_prefix+'.pdf_annotations.json')\n",
    "        if not os.path.exists(gt_file):\n",
    "            print(f\"{gt_file} doesn't exist\")\n",
    "            continue\n",
    "  \n",
    "        pred_df=process_layoutlm_pred_file(pred_file, line_threshold, os.path.basename(pred_file),cord)\n",
    "        if pred_df.shape[0] == 0:\n",
    "            print(f\"{pred_file} has no preds\")\n",
    "            continue\n",
    "        file_num += 1\n",
    "        if cord:\n",
    "            gt_df = process_cord_file(gt_file, pdf_filename=os.path.basename(gt_file))\n",
    "        else:\n",
    "            gt_df = process_cdip_gt(gt_file, pdf_filename=os.path.basename(gt_file))\n",
    "\n",
    "        print(gt_file)\n",
    "        pred_li = get_line_item_dic(pred_df, cord.FR)\n",
    "        gt_li = get_line_item_dic(gt_df, cord,FR)\n",
    "        pred_hed_lists.append(pred_li)\n",
    "        gt_hed_lists.append(gt_li)\n",
    "        \n",
    "        df = get_matched_gt_pred(gt_df, pred_df)\n",
    "        df.loc[:, 'file'] = os.path.basename(gt_file)\n",
    "        final_df = final_df.append(df, sort=True, ignore_index=True)     \n",
    "    final_df = final_df.fillna(0)\n",
    "    final_df['pred_text'] = final_df['pred_text'].replace(0, '')\n",
    "    final_df['gt_text'] = final_df['gt_text'].replace(0, '')\n",
    "    return final_df, file_num, gt_hed_lists, pred_hed_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_df_FR(PRED_DIR,GT_DIR,cord):\n",
    "    final_df = pd.DataFrame()\n",
    "    file_num = 0\n",
    "    gt_hed_lists = []\n",
    "    pred_hed_lists = []\n",
    "    for pred in os.listdir(PRED_DIR):\n",
    "        if pred == '.DS_Store':\n",
    "            continue   \n",
    "        if cord:\n",
    "            gt_file = os.path.join(GT_DIR, pred)\n",
    "        else:\n",
    "            gt_file = os.path.join(GT_DIR, pred[:-5]+'.pdf_annotations.json')\n",
    "        pred_file = os.path.join(PRED_DIR, pred)\n",
    "        if not os.path.exists(gt_file):\n",
    "            continue\n",
    "        pred_df,item_df,_,_ = process_pred_file(pred_file, pdf_filename=pred,multiplier=multiplier)\n",
    "        pred_df = pred_df[pred_df['label'].notna()]\n",
    "        if len(item_df) > 0:\n",
    "            item_df['label'] = item_df['label'].map(field_mapping)\n",
    "            item_df = item_df[item_df['label'].notna()]\n",
    "            pred_df = pred_df.append(item_df, sort=True, ignore_index=True)\n",
    "        if pred_df.shape[0] == 0:\n",
    "            continue\n",
    "        file_num += 1\n",
    "        if cord:\n",
    "            gt_df = process_cord_file(gt_file, os.path.basename(gt_file))\n",
    "        else:\n",
    "            gt_df = process_cdip_gt(gt_file, os.path.basename(gt_file))\n",
    "        gt_df['label'] = gt_df[gt_df['label'].apply(lambda x: x in field_mapping.keys())]\n",
    "        gt_df['label'] = gt_df['label'].map(field_mapping)\n",
    "        gt_df = gt_df[gt_df['label'].notna()]\n",
    "        pred_df = pred_df[pred_df['label'].apply(lambda x: x in field_mapping.values())]\n",
    "        pred_df = pred_df[pred_df['label'].notna()]\n",
    "        \n",
    "        pred_li = get_line_item_dic(pred_df,cord,FR)\n",
    "        gt_li = get_line_item_dic(gt_df,cord,FR)\n",
    "        pred_hed_lists.append(pred_li)\n",
    "        gt_hed_lists.append(gt_li)\n",
    "        \n",
    "        df = get_matched_gt_pred(gt_df, pred_df)\n",
    "        df.loc[:, 'file'] = os.path.basename(pred)\n",
    "        final_df = final_df.append(df, sort=True, ignore_index=True)\n",
    "            \n",
    "    final_df = final_df[final_df['label'].notna()]\n",
    "    final_df = final_df.fillna(0)\n",
    "    final_df['pred_text'] = final_df['pred_text'].replace(0, '')\n",
    "    final_df['gt_text'] = final_df['gt_text'].replace(0, '')\n",
    "    return final_df, file_num, gt_hed_lists, pred_hed_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match ground truth and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ng492mh/anaconda3/envs/sdg/lib/python3.7/site-packages/pandas/core/reshape/merge.py:1100: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation\n",
      "  UserWarning,\n",
      "/Users/ng492mh/anaconda3/envs/sdg/lib/python3.7/site-packages/pandas/core/frame.py:4238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(**kwargs)\n",
      "/Users/ng492mh/anaconda3/envs/sdg/lib/python3.7/site-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "if FR:\n",
    "    final_df,file_num, gt_hed_lists, pred_hed_lists = get_merged_df_FR(PRED_DIR,GT_DIR,cord)\n",
    "else:\n",
    "    final_df,file_num, gt_hed_lists, pred_hed_lists = get_merged_df(PRED_DIR,GT_DIR,line_threshold,cord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>gt_bbox</th>\n",
       "      <th>gt_group_label</th>\n",
       "      <th>gt_text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_bbox</th>\n",
       "      <th>pred_group_label</th>\n",
       "      <th>pred_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, gt_bbox, gt_group_label, gt_text, label, pred_bbox, pred_group_label, pred_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1013, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['pred_text']==''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df['gt_text']==''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>gt_bbox</th>\n",
       "      <th>gt_group_label</th>\n",
       "      <th>gt_text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_bbox</th>\n",
       "      <th>pred_group_label</th>\n",
       "      <th>pred_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORD_001_test_receipt_00056.json</td>\n",
       "      <td>(250, 1050, 562, 1089)</td>\n",
       "      <td>3</td>\n",
       "      <td>AIR MINERAL</td>\n",
       "      <td>ItemName</td>\n",
       "      <td>[251.4, 1053.6, 553.6, 1088.4]</td>\n",
       "      <td>1</td>\n",
       "      <td>AIR MINERAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CORD_001_test_receipt_00056.json</td>\n",
       "      <td>(787, 1045, 928, 1081)</td>\n",
       "      <td>3</td>\n",
       "      <td>8,181</td>\n",
       "      <td>ItemTotalPrice</td>\n",
       "      <td>[768, 1044, 926, 1083]</td>\n",
       "      <td>1</td>\n",
       "      <td>· 8, 181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CORD_001_test_receipt_00056.json</td>\n",
       "      <td>(824, 1136, 928, 1174)</td>\n",
       "      <td>4</td>\n",
       "      <td>818</td>\n",
       "      <td>Tax</td>\n",
       "      <td>[819, 1136, 916, 1173]</td>\n",
       "      <td>0</td>\n",
       "      <td>· 818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CORD_001_test_receipt_00056.json</td>\n",
       "      <td>(612, 1182, 922, 1222)</td>\n",
       "      <td>5</td>\n",
       "      <td>8,999</td>\n",
       "      <td>Total</td>\n",
       "      <td>[608.9, 1182, 893.1, 1221.5]</td>\n",
       "      <td>0</td>\n",
       "      <td>· 8,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CORD_001_test_receipt_00056.json</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Subtotal</td>\n",
       "      <td>[766.1, 1084.5, 924.9, 1130.3]</td>\n",
       "      <td>0</td>\n",
       "      <td>· 8, 181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file                 gt_bbox  gt_group_label  \\\n",
       "0  CORD_001_test_receipt_00056.json  (250, 1050, 562, 1089)               3   \n",
       "1  CORD_001_test_receipt_00056.json  (787, 1045, 928, 1081)               3   \n",
       "2  CORD_001_test_receipt_00056.json  (824, 1136, 928, 1174)               4   \n",
       "3  CORD_001_test_receipt_00056.json  (612, 1182, 922, 1222)               5   \n",
       "4  CORD_001_test_receipt_00056.json                       0               0   \n",
       "\n",
       "       gt_text           label                       pred_bbox  \\\n",
       "0  AIR MINERAL        ItemName  [251.4, 1053.6, 553.6, 1088.4]   \n",
       "1        8,181  ItemTotalPrice          [768, 1044, 926, 1083]   \n",
       "2          818             Tax          [819, 1136, 916, 1173]   \n",
       "3        8,999           Total    [608.9, 1182, 893.1, 1221.5]   \n",
       "4                     Subtotal  [766.1, 1084.5, 924.9, 1130.3]   \n",
       "\n",
       "   pred_group_label    pred_text  \n",
       "0                 1  AIR MINERAL  \n",
       "1                 1     · 8, 181  \n",
       "2                 0        · 818  \n",
       "3                 0      · 8,999  \n",
       "4                 0     · 8, 181  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IoU metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_metrics(df):\n",
    "    if not df['gt_bbox']:\n",
    "        df['FP'] = 1\n",
    "        ious = 0\n",
    "    elif not df['pred_bbox']:\n",
    "        df['FN'] = 1\n",
    "        ious = 0\n",
    "    else:\n",
    "        ious = iou(df['gt_bbox'], df['pred_bbox'])\n",
    "        df['TP'] = 1\n",
    "        num = 1\n",
    "    df['iou'] = ious\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(df):\n",
    "    deno = df['TP'] + df['FP']\n",
    "    if deno == 0:\n",
    "        return 0\n",
    "    precision = df['TP'] / deno\n",
    "    return precision\n",
    "def get_recall(df):\n",
    "    deno = df['TP'] + df['FN']\n",
    "    if deno == 0:\n",
    "        return 0\n",
    "    recall = df['TP'] / deno\n",
    "    return recall\n",
    "def get_f1(df,prec_col, recall_col):\n",
    "    deno = df[prec_col] + df[recall_col]\n",
    "    if deno == 0:\n",
    "        return 0\n",
    "    f1 = 2*df[prec_col]*df[recall_col] / deno\n",
    "    return f1\n",
    "def get_iou_label(df):\n",
    "    d = {}\n",
    "    TP = sum(df[\"TP\"])\n",
    "    FN = sum(df[\"FN\"])\n",
    "    FP = sum(df[\"FP\"])\n",
    "    count = len(df)\n",
    "    precision = 0 if TP+FP == 0 else TP/(TP+FP)\n",
    "    recall = 0 if TP+FN==0 else TP/(TP+FN)\n",
    "    f1 = 0 if precision+recall==0 else 2*precision*recall/(precision+recall)\n",
    "    d['iou_precision'] = precision\n",
    "    d['iou_recall']=recall\n",
    "    d['iou_f1']=f1\n",
    "    d['support'] = int(count)\n",
    "    return pd.Series(d, index=['iou_precision', 'iou_recall', 'iou_f1', 'support'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_weighted_mean(iou_metrics_df,prefix, volumn_col):\n",
    "    total = iou_metrics_df[volumn_col].sum() + 1e-10\n",
    "    prec_mean = sum(iou_metrics_df[prefix+'_precision']*iou_metrics_df[volumn_col]) / total\n",
    "    rec_mean = sum(iou_metrics_df[prefix+'_recall']*iou_metrics_df[volumn_col]) / total\n",
    "    f1_mean = sum(iou_metrics_df[prefix+'_f1']*iou_metrics_df[volumn_col]) / total\n",
    "    return pd.DataFrame([{'prec_mean':round(prec_mean,2), 'recall_mean':round(rec_mean,2),'f1_mean':round(f1_mean,2)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_metrics_df(df):\n",
    "    df = df.loc[:, ['label','gt_bbox', 'pred_bbox']]\n",
    "    metrics_df = df.apply(get_iou_metrics, axis=1).fillna(0)\n",
    "    iou_metrics_df=metrics_df[['FN','FP','TP','label']].groupby('label').apply(get_iou_label)\n",
    "    mean_df = get_iou_weighted_mean(iou_metrics_df,'iou','support')\n",
    "    return iou_metrics_df, mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_metrics_df, iou_mean_df = get_iou_metrics_df(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iou_precision</th>\n",
       "      <th>iou_recall</th>\n",
       "      <th>iou_f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ItemName</th>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.880851</td>\n",
       "      <td>0.877119</td>\n",
       "      <td>265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemPrice</th>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemQuantity</th>\n",
       "      <td>0.880503</td>\n",
       "      <td>0.657277</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemTotalPrice</th>\n",
       "      <td>0.902655</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtotal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tax</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                iou_precision  iou_recall    iou_f1  support\n",
       "label                                                       \n",
       "ItemName             0.873418    0.880851  0.877119    265.0\n",
       "ItemPrice            0.976190    0.621212  0.759259     67.0\n",
       "ItemQuantity         0.880503    0.657277  0.752688    232.0\n",
       "ItemTotalPrice       0.902655    0.886957  0.894737    252.0\n",
       "Subtotal             0.000000    0.000000  0.000000     58.0\n",
       "Tax                  0.958333    0.522727  0.676471     45.0\n",
       "Total                0.942529    0.921348  0.931818     94.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prec_mean  recall_mean  f1_mean\n",
       "0       0.85         0.75     0.79"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_metrics(df):\n",
    "    df = df.loc[:, ['pred_text','gt_text','label']]\n",
    "    df['direct'] = (df['gt_text'] == df['pred_text']).astype(float)\n",
    "    df[\"gt_text_alpha\"] = df[\"gt_text\"].apply(lambda x: pattern.sub('',x)) # Remove non-alphanumeric characters\n",
    "    df[\"pred_text_alpha\"] = df[\"pred_text\"].apply(lambda x: pattern.sub('',x)) # Remove non-alphanumeric characters\n",
    "    df['direct_alpha'] = (df['gt_text_alpha'] == df['pred_text_alpha']).astype(float)\n",
    "    df['levenshtein'] = df.apply(lambda x: levenshtein_distance(x['gt_text'], x['pred_text'], normalize=True), axis=1)\n",
    "    df['levenshtein_alpha'] = df.apply(lambda x: levenshtein_distance(x['gt_text_alpha'], x['pred_text_alpha'], normalize=True), axis=1)\n",
    "    df['lcsubsequence'] = df.apply(lambda x: lc_subsequence(x['gt_text'], x['pred_text']), axis=1)\n",
    "    df['TP'] = df['lcsubsequence'].apply(lambda x:x[0])\n",
    "    df['FP'] = df['lcsubsequence'].apply(lambda x:x[1])\n",
    "    df['FN'] = df['lcsubsequence'].apply(lambda x:x[2])\n",
    "    df['lcs_precision'] = df.apply(get_precision, axis=1)\n",
    "    df['lcs_recall'] = df.apply(get_recall, axis=1)\n",
    "    df['lcs_f1'] = df.apply(lambda x:get_f1(x, 'lcs_precision', 'lcs_recall'), axis=1) \n",
    "    counts = pd.Series(df.groupby(['label']).count()['gt_text'], name='count')\n",
    "    df.drop(columns=['pred_text','gt_text','TP','FP','FN','gt_text_alpha','pred_text_alpha'], inplace=True)\n",
    "    metrics_df = pd.merge(df.groupby(['label']).mean(), counts, on=['label'])\n",
    "    metrics_df['direct_alpha'] = metrics_df['direct_alpha'].apply(lambda x: round(x,6))\n",
    "    metrics_df['levenshtein'] = metrics_df['levenshtein'].apply(lambda x: round(x,6))\n",
    "    metrics_df['levenshtein_alpha'] = metrics_df['levenshtein_alpha'].apply(lambda x: round(x,6))\n",
    "    return metrics_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_df=get_text_metrics(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direct</th>\n",
       "      <th>direct_alpha</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>levenshtein_alpha</th>\n",
       "      <th>lcs_precision</th>\n",
       "      <th>lcs_recall</th>\n",
       "      <th>lcs_f1</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ItemName</th>\n",
       "      <td>0.664151</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.756157</td>\n",
       "      <td>0.757759</td>\n",
       "      <td>0.771977</td>\n",
       "      <td>0.762168</td>\n",
       "      <td>0.764449</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemPrice</th>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.605188</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.605188</td>\n",
       "      <td>0.609453</td>\n",
       "      <td>0.607157</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemQuantity</th>\n",
       "      <td>0.577586</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.585206</td>\n",
       "      <td>0.592098</td>\n",
       "      <td>0.585206</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.586806</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemTotalPrice</th>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.793934</td>\n",
       "      <td>0.802646</td>\n",
       "      <td>0.794596</td>\n",
       "      <td>0.799036</td>\n",
       "      <td>0.796328</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtotal</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tax</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.474074</td>\n",
       "      <td>0.537284</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.487407</td>\n",
       "      <td>0.481852</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.856095</td>\n",
       "      <td>0.867173</td>\n",
       "      <td>0.856095</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>0.860073</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  direct  direct_alpha  levenshtein  levenshtein_alpha  \\\n",
       "label                                                                    \n",
       "ItemName        0.664151      0.679245     0.756157           0.757759   \n",
       "ItemPrice       0.567164      0.641791     0.605188           0.641791   \n",
       "ItemQuantity    0.577586      0.586207     0.585206           0.592098   \n",
       "ItemTotalPrice  0.746032      0.793651     0.793934           0.802646   \n",
       "Subtotal        0.000000      0.000000     0.000000           0.000000   \n",
       "Tax             0.400000      0.511111     0.474074           0.537284   \n",
       "Total           0.787234      0.851064     0.856095           0.867173   \n",
       "\n",
       "                lcs_precision  lcs_recall    lcs_f1  count  \n",
       "label                                                       \n",
       "ItemName             0.771977    0.762168  0.764449    265  \n",
       "ItemPrice            0.605188    0.609453  0.607157     67  \n",
       "ItemQuantity         0.585206    0.594828  0.586806    232  \n",
       "ItemTotalPrice       0.794596    0.799036  0.796328    252  \n",
       "Subtotal             0.000000    0.000000  0.000000     58  \n",
       "Tax                  0.481481    0.487407  0.481852     45  \n",
       "Total                0.856095    0.865248  0.860073     94  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prec_mean  recall_mean  f1_mean\n",
       "0       0.67         0.68     0.67"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_iou_weighted_mean(lcs_df,'lcs', 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HED for Line items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_hed_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_hed_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tax': '818',\n",
       " 'Total': '8,999',\n",
       " 'Items': [{'ItemName': 'AIR MINERAL', 'ItemTotalPrice': '8,181'}]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_hed_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Items': [{'ItemName': 'AIR MINERAL', 'ItemTotalPrice': '· 8, 181'}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_hed_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hed_document(gt_item_list, pred_item_list):\n",
    "    file_results = [hed(gt_item, pred_item)[0] for gt_item, pred_item in zip(gt_item_list, pred_item_list)]\n",
    "    file_hed_df = pd.DataFrame(np.stack(file_results), columns=['TP', 'FP', 'FN'])\n",
    "    file_hed_df['precision'] = file_hed_df.apply(get_precision, axis=1)\n",
    "    file_hed_df['recall'] = file_hed_df.apply(get_recall, axis=1)\n",
    "    file_hed_df['f1-score'] = file_hed_df.apply(lambda x: get_f1(x, \"precision\", \"recall\"), axis=1)\n",
    "    return file_hed_df.drop(columns=['TP', 'FP', 'FN']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hed_label(gt_item_list, pred_item_list):\n",
    "    results = [hed(gt_item, pred_item)[1] for gt_item, pred_item in zip(gt_item_list, pred_item_list)]\n",
    "    hed_df = pd.concat([pd.DataFrame(result).T.reset_index()  for i, result in enumerate(results)])\n",
    "    hed_df = hed_df.rename(columns={0:'TP', 1:'FP', 2:'FN'})\n",
    "    hed_df['precision'] = hed_df.apply(get_precision, axis=1)\n",
    "    hed_df['recall'] = hed_df.apply(get_recall, axis=1)\n",
    "    hed_df['f1-score'] = hed_df.apply(lambda x: get_f1(x, \"precision\", \"recall\"), axis=1)\n",
    "    label_df = hed_df.drop(columns=['TP', 'FP', 'FN']).groupby('index').mean()\n",
    "    mean_df = hed_df.drop(columns=['TP', 'FP', 'FN']).mean()\n",
    "    return label_df, mean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-level Mean HED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.909858\n",
       "recall       0.715767\n",
       "f1-score     0.784926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hed_document(gt_hed_lists, pred_hed_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label-level HED and Mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df, mean_df = get_hed_label(gt_hed_lists, pred_hed_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision    0.597745\n",
       "recall       0.538157\n",
       "f1-score     0.553726\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ItemName</th>\n",
       "      <td>0.952076</td>\n",
       "      <td>0.864072</td>\n",
       "      <td>0.887519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemPrice</th>\n",
       "      <td>0.724747</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.683808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemQuantity</th>\n",
       "      <td>0.741972</td>\n",
       "      <td>0.602681</td>\n",
       "      <td>0.634511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemTotalPrice</th>\n",
       "      <td>0.906737</td>\n",
       "      <td>0.862978</td>\n",
       "      <td>0.876569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tax</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                precision    recall  f1-score\n",
       "index                                        \n",
       "ItemName         0.952076  0.864072  0.887519\n",
       "ItemPrice        0.724747  0.663939  0.683808\n",
       "ItemQuantity     0.741972  0.602681  0.634511\n",
       "ItemTotalPrice   0.906737  0.862978  0.876569\n",
       "Tax              0.000000  0.000000  0.000000\n",
       "Total            0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line threshold vs Rule performance vs PSL performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final = []\n",
    "# for threshold in [1,3,5,7,10,15,20,25,30,40,45,50,60,70,80]:\n",
    "#     final_df,file_num, gt_item_list, pred_item_list = get_merged_df(PRED_DIR,GT_DIR, threshold)\n",
    "#     data = get_hed_document(gt_item_list, pred_item_list).to_dict()\n",
    "#     data[\"Y-distance threshold\"] = threshold\n",
    "#     final.append(data)\n",
    "# pd.DataFrame(final).to_csv(\"Y_distance_threshold_vs_metrics_nopsl.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
